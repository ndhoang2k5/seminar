\documentclass{article} % Định dạng tài liệu
\usepackage[T5]{fontenc}
\usepackage[vietnamese]{babel}
\usepackage{graphicx} % Hỗ trợ chèn hình ảnh
\usepackage{amsmath, amssymb} % Gói toán học
\usepackage{hyperref} % Hỗ trợ liên kết
\usepackage{natbib}  % hoặc biblatex nếu bạn dùng hệ thống trích dẫn khác
\usepackage{natbib} % Hỗ trợ trích dẫn tài liệu
\usepackage{booktabs} % Định dạng bảng
\usepackage{geometry} % Tùy chỉnh lề
\usepackage{float} % Định dạng hình ảnh
\usepackage{fancyhdr} % Định dạng header và footer
\usepackage{setspace} % Định dạng khoảng cách giữa dòng
\usepackage{enumitem}
\onehalfspacing
\title{Hiệu suất và hiệu của của những mô hình ngôn ngữ lớn LLMs trong gán nhãn dữ liệu kinh tế}
\author{
    Nguyễn Duy Hoàng - 23020368\\
    Nguyễn Trung Hiếu - 23020366\\
    Dương Lý Khánh Hạ - 23020362
}
\begin{document}


\maketitle
\tableofcontents


\begin{abstract}
    Nghiên cứu về hiệu suất và hiệu quả của những mô hình ngôn ngữ lớn LMMs trong gán nhãn dữ liệu kinh tế
\end{abstract}

\section{\textbf{Giới thiệu}}
\subsection{Bối cảnh nghiên cứu}

Các mô hình ngôn ngữ lớn LLMs đã không còn quá xa lạ với mọi người trong thời đại 4.0, 
chúng ta biết rằng những mô hình này đã đạt được nhiều thành tựu to lớn trong nhiều lĩnh vực khác nhau.
Tuy nhiên, trong lĩnh vực kinh tế, việc áp dụng những mô hình này để gán nhãn dữ liệu vẫn còn khá mới mẻ
và chưa được nghiên cứu nhiều. Điều đó làm cho mọi người quan ngại về hiệu suất của những mô hình này trong 
công việc gán nhán dữ liệu kinh tế.

\subsection{Mục tiêu nghiên cứu}

\begin{itemize}

\item Đánh giá hiệu quả của những mô hình ngôn ngữ lớn trong việc gán nhãn trên những tập dữ liệu 
tổng quát và chuyên biệt.
\item So sánh độ chính xác, tốc độ và chi phí giữa phương pháp truyền thống và phương pháp sử dụng LLMs.
\item Phân tích chi tiết kết quả của các phương pháp, mô hình được đưa vào sử dụng
\item Tổng hợp kết quả để đưa ra những nhận xét và đề xuất cho việc sử dụng mô hình ngôn ngữ lớn LLMs trong việc gán nhãn dữ liệu kinh tế.
\item Đề xuất hướng phát triển cho việc nghiên cứu trong tương lai.

\end{itemize}

\subsection{Phạm vi nghiên cứu}

\noindent
\textbullet\ Những tập dữ liệu được đưa vào nghiên cứu: 

\hspace{10pt}- \hyperlink{ref:refind2023}{REFinD}: Tập dữ liệu chuyên biệt về kinh tế

\hspace{10pt}- ............

\noindent
\textbullet\ Các mô hình ngôn ngữ lớn được sử dụng trong nghiên cứu :

\hspace{10pt}- chatGP, GPT-3, BERT, RoBERTa, T5, ...

\noindent
\textbullet\ Các tiêu chí đánh giá hiệu suất

\section{Tổng quan về LMMs và gán nhãn dữ liệu kinh tế}

\subsection{Mô hình ngôn ngữ lớn (LMMs) là gì?}

\hspace{10pt} Mô hình ngôn ngữ lớn (Large Language Models - LLMs) là các mô hình học sâu (deep learning) được huấn luyện trên tập 
dữ liệu văn bản khổng lồ nhằm hiểu, tạo, và thao tác với ngôn ngữ tự nhiên. Chúng được xây dựng dựa trên kiến trúc Transformer, 
nổi bật với cơ chế self-attention giúp mô hình hiểu được ngữ cảnh của từ trong câu và sinh văn bản có ý nghĩa.

\hspace{10pt} \textbf{Các mô hình LLMs phổ biến}: GPT-3, BERT, RoBERTa, T5, chatGP, ...

\hspace{10pt} \textbf{Nguyên lý hoạt động}: Mô hình học máy hoạt động theo quy trình cơ bản như sau

\hspace{35pt} 1.\textbf{tiền huấn luyện}: Mô hình được huấn luyện trên tập dữ liệu lớn để hiểu ngôn ngữ tự nhiên

\hspace{35pt} 2.\textbf{tinh chỉnh}: Mô hình được tinh chỉnh trên tập dữ liệu nhỏ để thực hiện các nhiệm vụ cụ thể

\hspace{35pt} 3.\textbf{dự đoán}: Mô hình được sử dụng để dự đoán, phân loại, sinh văn bản, ...

\subsection{Gán nhãn dữ liệu kinh tế} 

\subsubsection{Gán nhãn dữ liệu là gì?}
Gán nhãn dữ liệu (Data Labeling) là quá trình gán các nhãn hoặc thông tin mô tả cho dữ liệu để giúp mô hình 
học máy (Machine Learning - ML) học cách nhận diện các mẫu (patterns). Dữ liệu đã được gán nhãn được gọi là dữ liệu 
có giám sát (labeled data) và thường được sử dụng trong các bài toán học có giám sát (Supervised Learning).

Ví dụ: 

\hspace{10pt}- Trong xử lý ngôn ngữ tự nhiên (NLP), gán nhãn dữ liệu có thể là việc xác định câu nào mang ý nghĩa tích cực hay tiêu cực (phân tích cảm xúc).

\hspace{10pt}- Trong nhận dạng hình ảnh, gán nhãn có thể là đánh dấu hình ảnh có chứa một con chó, mèo hoặc xe hơi.

\subsubsection{Vai trò của gán nhãn dữ liệu trong kinh tế}
\hspace{10pt} 1.Cải thiện độ chính xác trong phân tích kinh tế

2.Hỗ trợ mô hình hóa rủi ro và dự báo thị trường

3.Cải thiện hiệu suất dự báo kinh tế bằng AI

4.Hỗ trợ hoạch định chính sách kinh tế

5.Cá nhân hóa dịch vụ tài chính

\subsubsection{Các phương pháp gán nhãn dữ liệu kinh tế truyền thống}

\textbf{1}.Gán nhãn thủ công(manutual labeling)

\hspace{10pt} Các chuyên gia hoặc nhân viên nhập liệu trực tiếp xem xét dữ liệu và gán nhãn tương ứng.\\
\textbf{Ưu điểm}: Chính xác, đáng tin cậy\\
\textbf{Nhược điểm}: Tốn kém, tốn thời gian, không thể áp dụng cho dữ liệu lớn

\textbf{2}.Gán nhãn bằng crowdsourcing (Crowdsourced Labeling)

\hspace{10pt} Nhiều người tham gia (crowd workers) cùng thực hiện gán nhãn thông qua các nền tảng như Amazon Mechanical Turk, Appen, hoặc Labelbox.\\
\textbf{Ưu điểm}: Chi phí thấp, nhanh chóng\\
\textbf{Nhược điểm}: Chất lượng không đảm bảo, cần kiểm soát chất lượng

\textbf{3}. Học bám sát (Semi-supervised Learning - SSL)

\hspace{10pt} Kết hợp một lượng nhỏ dữ liệu có gán nhãn với một lượng lớn dữ liệu chưa gán nhãn. 
Sử dụng mô hình AI để dự đoán nhãn cho dữ liệu chưa gán nhãn, sau đó xác minh và tinh chỉnh nhãn.\\
\textbf{Ưu điểm} : Tiết kiệm chi phí, có thể sử dụng lượng lớn dữ liệu chưa gán nhãn để cải thiện độ chính xác\\
\textbf{Nhược điểm} : Mô hình ban đầu có thể tạo ra nhãn sai nếu không được tinh chỉnh đúng cách, cần một lượng dữ liệu có nhãn chất lượng cao để huấn luyện mô hình

\subsubsection{Phương pháp gán nhãn dữ liệu kinh tế sử dụng LLMs}

\textbf{1}. Gán nhãn bán tự động (Human-in-the-loop)

\hspace{10pt} \textbullet\ LLMs gợi ý nhãn và con người xác nhận hoặc chỉnh sửa.

\hspace{10pt} \textbullet\ Giúp tiết kiệm thời gian so với gán nhãn thủ công.

\textbf{2}. Gán nhãn tự động (Auto-labeling)

\hspace{10pt} \textbullet\ LLMs tự động gán nhãn dựa trên ngữ cảnh và dữ liệu huấn luyện.

\hspace{10pt} \textbullet\ Phù hợp với tập dữ liệu lớn nhưng cần kiểm tra chất lượng.

\textbf{3}. Học có giám sát kết hợp LLMs (Supervised Learning with LLMs)

\hspace{10pt} \textbullet\ Dùng LLMs để gán nhãn dữ liệu chưa có nhãn, sau đó sử dụng tập dữ liệu này để huấn luyện mô hình học có giám sát.

\hspace{10pt} \textbullet\ Giúp cải thiện độ chính xác của mô hình AI dự báo kinh tế

\textbf{4}. Gán nhãn dữ liệu bằng phương pháp few-shot learning

\hspace{10pt} \textbullet\ Cung cấp một số ví dụ mẫu, sau đó LLMs suy luận và gán nhãn dữ liệu mới.

\hspace{10pt} \textbullet\ Giảm phụ thuộc vào tập dữ liệu có nhãn lớn.

\textbf{5}. Gán nhãn dữ liệu bằng phương pháp zero shot learning

\hspace{10pt} \textbullet\ LLMs gán nhãn mà không cần dữ liệu huấn luyện trước, chỉ dựa vào kiến thức sẵn có.

\hspace{10pt} \textbullet\ Tiết kiệm chi phí nhưng có thể không chính xác bằng các phương pháp khác.

\section{Phương pháp nghiên cứu}

\subsection{Dữ liệu}
Tập dữ liệu kinh tế \hyperlink{ref:refind2023}{REFinD}

\begin{itemize}
    \item Nguồn gốc và lý do chọn REFINDREFIND: Tập dữ liệu này được trích xuất từ các báo cáo hàng quý và hàng năm của các công ty giao dịch công khai. 
REFinD là tập dữ liệu lớn nhất hiện có dành cho nhiệm vụ trích xuất quan hệ trong lĩnh vực tài chính. Đây cũng là tập dữ liệu tài chính duy 
nhất có thể tiếp cận với các gán nhãn từ cả chuyên gia và lao động đám đông.
    \item Kích thước và các loại thực thể: REFinD bao gồm 28.676 mẫu dữ liệu, với 22 loại quan hệ trên 8 cặp thực thể khác nhau. 
Một tập dữ liệu tài chính khác là FinRED (Sharma et al. 2022) có quy mô nhỏ hơn đáng kể (6.767 mẫu và 29 loại quan hệ), 
nhưng không công khai dữ liệu gán nhãn từ từng lao động đám đông riêng lẻ.
Thí nghiệm này sử dụng 3.598 mẫu từ tập kiểm tra (test set) của REFinD, do chi phí sử dụng LLM cao.

\end{itemize}

\subsection{Models}
\hspace{10pt} Thí nghiệm này đã sử dụng ba mô hình ngôn ngữ lớn (LLM) gồm GPT-4, PaLM 2, và MPT Instruct. 
Các mô hình này được chọn dựa trên hiệu suất xuất sắc của chúng trong các bảng xếp hạng chuẩn hóa (benchmark leaderboards), 
khả năng truy cập, khả dụng của API và giấy phép sử dụng linh hoạt.\\
Ba mô hình với kích thước khác nhau: 
\begin{itemize}
    \item Chat GPT-4 có khoảng 1700 tỉ tham số
    \item PaLM có khoảng có 340 tỉ tham số
    \item MPT Instruct với khoảng 7 tỉ tham số
\end{itemize}
Những thiết lập nhỏ để thí nghiệm các mô hình:
\begin{itemize}
    \item với mỗi mô hình ta sẽ thực hiện thí nghiệm với hai mức nhiệt độ khác nhau là 0.2 và 0.7 nhằm kiểm kiểm tra tác
động của mức độ ngâu nhiên lên hiệu suất mô hình  % nhiệt độ ở đây đang nói đến mức độ sinh từ ngẫu nhiên của mô hình VD 0.2 thì mô hình sẽ chọn những từ có xác suất cao nhất dẫn đến đầu ra ổn định , ít sáng tạo và logic hơn
    \item Mô hình không đặt được random seed cho nên sẽ cho ra những kết quả khác nhau %random seed : cứ hiểu đơn giản là cái này cho 1 iput nhưng lại cho ra output khác nhau
\end{itemize}

\subsection{Prompts và các thước đo đánh giá hiệu suất của mô hình}
\subsubsection{Prompts}
Chất lượng của lời nhắc hướng dẫn mô hình ngôn ngữ lớn (LLM) ảnh hưởng đáng kể đến hiệu suất của chúng, tương tự như cách soạn hướng dẫn cho những người lao động đám đông.
Mỗi lời nhắc đầu vào bao gồm: 
\begin{itemize}
    \item Mô tả bằng văn bản nhiệm vụ.
    \item Một câu có các thực thể được đánh dấu.
    \item Danh sách các tùy chọn quan hệ (nhãn) được đánh số, cụ thể cho từng cặp thực thể.
\end{itemize}

Thí nghiệm này đã sử dụng 6 loại lời nhắc khác nhau và chia thành 3 nhóm: 

\begin{itemize}
    \item Nhóm 1: Zero-shot:
    \begin{itemize}[label=-]
        \item Lời nhắc đơn giản – Mô tả nhiệm vụ ngắn gọn bằng tiếng Anh đơn giản.
        \item Lời nhắc hướng dẫn đầy đủ – Phiên bản mở rộng với mô tả chi tiết hơn, 
    dựa trên hướng dẫn gán nhãn của tập dữ liệu REFinD được cung cấp cho người lao động trên nền tảng Amazon Mechanical Turk (MTurk).
    \end{itemize}
    \item Nhóm 2: Few-shot:
    \begin{itemize}[label=-]
        \item 1-shot – Dựa trên lời nhắc hướng dẫn đầy đủ và thêm một ví dụ về nhiệm vụ, phù hợp với loại cặp thực thể cụ thể.
        \item 5-shot – Giống như 1-shot, nhưng bao gồm năm ví dụ thay vì một.
    \end{itemize}
    \item Nhóm 3: Few-shot Chain-of-Thought (CoT):
    \begin{itemize}[label=-]
        \item 1-shot CoT – Kết hợp giữa mô tả nhiệm vụ, ví dụ và cả suy luận giải thích lý do cho từng quyết định.
        \item 5-shot CoT – Phiên bản mở rộng của 1-shot CoT, sử dụng năm ví dụ thay vì một.
    \end{itemize}
\end{itemize}

\subsubsection{Thước đo đánh giá hiệu suất của mô hình}

\textbf{1}.Mô hình sẽ được đánh giá bằng cách so sánh với các nhãn được gán bởi chuyên gia bằng 2 thứơc đo chính:
\begin{itemize}
    \item Độ chính xác(acurrancy): là tỉ lệ giữa số lượng dự đoán đúng và tổng số dự đoán.
    \item F1-score: là một thước đo tổng hợp của độ chính xác và độ phủ của mô hình, được tính bằng công thức: 
    \[F1 = 2 \times \frac{precision \times recall}{precision + recall}\]
\end{itemize}

\textbf{2}.Chỉ số tin cậy(Reliability Index - LLM-Rellndex):

\noindent
Đây là chỉ số để đánh gía mức độ tin cậy của mô hình.Để tổng hợp nhãn cuối cùng cho mỗi mẫu dữ liệu từ nhiều mô hình gán nhãn khác nhau, 
cách tiếp cận đơn giản nhất là đếm số phiếu bầu cho mỗi nhãn từ K người gán nhãn. Tuy nhiên, phương pháp này có nhược điểm: 
nếu mỗi người gán nhãn chọn một nhãn khác nhau, thì việc chọn nhãn cuối cùng sẽ mang tính ngẫu nhiên.
Do đó, chúng tôi cải tiến cách tính điểm số phiếu bầu bằng cách tính đến mức độ tương đồng giữa các nhãn theo đánh giá của chuyên gia bằng chỉ số Rellndex.

Chỉ số này giúp xác định nhãn nào là đáng tin cậy nhất trong mỗi trường hợp và cũng có thể dùng để lọc ra những trường hợp cần sự can thiệp của chuyên gia.

Cách tính của Rellndex: 
\begin{itemize}
    \item Đối với mỗi nhãn dán l, chúng tôi tính điểm phiếu bầu có trọng số như sau \\
$$ \text{vote}(i, j) = \text{sim}(a_i, l) $$
    \item Sau đó tính điểm tin cậy của phiếu bầu bằng cách lấy trung bình điểm phiếu bầu\\
$$ \text{confid}(l) = \frac{1}{K} * \sum_{1}^{K}{\text{vote}(i, l)} $$
    \item Cuối cùng chỉ số Rellndex được xác định là độ tin cậy cao nhất trong số các nhãn dán được đề xuất\\
$$ \text{Rellndex} = \max_{l}{\text{confid}(l)} $$
\end{itemize}

\textbf{3}.Chi phí:

Đối với các mô hình được truy cập qua API, chi phí trên mỗi mẫu phụ thuộc vào số lượng tokens (đối với GPT-4) hoặc ký tự (đối với PaLM 2) 
trong cả lời nhắc đầu vào và đầu ra được tạo ra. Do đó, chi phí gán nhãn được tính bằng cách nhân số lượng trung bình của tokens/ký tự trong lời nhắc 
và đầu ra với số lượng mẫu, sau đó nhân với giá mỗi token/ký tự.
\[
\text{Chi phí} = \frac{\text{Số token/ký tự đầu vào, đầu ra}}{\text{Giá mỗi token/ký tự}} \times \text{Số mẫu}
\]

 kdfjalsf sksk


\end{document}
